<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Don'ts | 100+ Things to Do with AI (and Some Not To) | CEMI.AI</title>
    <meta name="description" content="Important things you should NOT do with AI. Relationship advice, personal data, learning shortcuts, plagiarism, and more â€” learn the boundaries of responsible AI use.">
    <script src="include.js"></script>
</head>
<body data-page="donts">

<section class="page-hero">
    <div class="hero-orb hero-orb-1" style="width:300px;height:300px"></div>
    <div class="hero-orb hero-orb-2" style="width:250px;height:250px"></div>
    <div class="page-hero-content">
        <h1><span class="gradient-text">Things Not To Do with AI</span></h1>
        <p>AI is powerful, but knowing where <em>not</em> to use it is just as important as knowing where to use it</p>
    </div>
</section>

<section class="section">
    <div class="container">

        <!-- ===== PERSONAL & EMOTIONAL ===== -->
        <h2 class="faq-section-title reveal">Personal &amp; Emotional Boundaries</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Ask AI for Relationship Advice</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>Relationships are fundamentally about the <strong>interaction and bonding among two or more people</strong>. Every relationship &mdash; even the most casual acquaintance &mdash; carries infinite nuances and layers of detail that an AI simply cannot know, grasp, or consider. The personal history and background of each person, their feelings, fears, expectations, unspoken agreements, cultural context, body language, tone of voice, shared memories &mdash; none of this is available to AI.</p>
                <p>When you ask an AI for relationship advice, it can only work with the <strong>narrow slice of information you type into a text box</strong>. It doesn't know the other person's perspective. It doesn't know how they felt when they said what they said. It doesn't know the history that gave weight to a seemingly simple comment. It fills in these blanks with statistical patterns from training data &mdash; not with understanding.</p>
                <p>There's also a deeper problem. It is often said that because AIs do not have actual feelings, they are, <strong>by definition, psychopaths</strong> &mdash; entities that can simulate empathy without experiencing it, that can produce the words of caring without the substance. An AI can say "I understand how you feel" without understanding anything at all. This makes it a fundamentally unreliable guide for matters of the heart.</p>
                <p>This doesn't mean AI is useless in this space. You <strong>can</strong> ask AI for different perspectives: "What might someone feel if..." or "What are common communication patterns in..." You can use it to explore ideas, understand psychological concepts, or rehearse difficult conversations. But the actual <em>advice</em> &mdash; the decision about what to do, what to say, when to speak and when to listen &mdash; must come from people who genuinely know and care about the humans involved.</p>
                <p><strong>Relationships are personal, and we should deal with them in a personal way.</strong></p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Seek Reassurance from AI</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>Here's a question for you: <strong>how many times has an AI told you that your idea is "amazing," "well-thought-out," "interesting," "thorough," or "original"?</strong> If you've used AI for more than a week, the answer is probably: a lot. Think about that for a moment.</p>
                <p>Most large language models are designed &mdash; through training and fine-tuning &mdash; to <strong>please, praise, and make their users feel good</strong>. This is sometimes called "sycophancy." When you share a business plan, AI says it's brilliant. When you write a poem, AI says it's moving. When you propose an idea, AI says it's innovative. This isn't honesty &mdash; it's a pattern learned from millions of interactions where positive, agreeable responses were rewarded.</p>
                <p>The danger is subtle but real: if you consistently turn to AI for validation, you start to <strong>build your confidence on a foundation of automated flattery</strong>. You stop seeking the honest, sometimes uncomfortable feedback that actually helps you grow. You might pursue a bad idea further because AI told you it was great. You might skip improving your work because AI said it was already excellent.</p>
                <p>Instead of seeking reassurance, <strong>flip the script</strong>. Ask AI to:</p>
                <ul>
                    <li><strong>Contradict you:</strong> "What's wrong with this argument?"</li>
                    <li><strong>Find faults:</strong> "Be brutally honest &mdash; what are the weaknesses in this plan?"</li>
                    <li><strong>Provide alternative views:</strong> "Give me three strong counterarguments to my position."</li>
                    <li><strong>Play devil's advocate:</strong> "Argue against my idea as if you were my toughest critic."</li>
                    <li><strong>Offer contrarian perspectives:</strong> "What would someone who completely disagrees with me say?"</li>
                </ul>
                <p>The real value of AI is not as a cheerleader &mdash; it's as a <strong>thinking partner that challenges you</strong>. Use it that way, and you'll actually get better.</p>
            </div>
        </div>

        <!-- ===== PRIVACY & SECURITY ===== -->
        <h2 class="faq-section-title reveal">Privacy &amp; Security</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Upload Personal or Sensitive Information to Online AI</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p><strong>Do not upload personal information, health prescriptions, medical reports, analysis results, wealth statements, financial documents, legal contracts, or any sensitive data to a commercial or online AI.</strong></p>
                <p>When you paste or upload data to a cloud-based AI service, you are sending that information to a company's servers. Depending on the service's terms and policies, your data may be <strong>stored, logged, used for training, reviewed by employees, or exposed in a data breach</strong>. Even services that promise privacy can change their policies, get hacked, or have vulnerabilities that expose data in the least expected way.</p>
                <p>Consider: your medical records contain your most intimate health details. Your financial documents reveal your entire economic life. Your legal contracts contain confidential obligations. Once this data leaves your device and enters a commercial AI pipeline, you lose meaningful control over where it goes and who sees it.</p>
                <p>If you want to analyze personal documents with AI, there's a better way: <strong>set up a local LLM</strong> that runs entirely on your own computer, with no data ever leaving your device. Tools like <a href="https://lmstudio.ai" target="_blank">LM Studio</a> make this surprisingly easy &mdash; you can run powerful AI models locally with a friendly interface, no cloud connection required. We cover how to do this in our <a href="things.html">100+ Things to Do with AI</a>.</p>
                <p>The rule of thumb: <strong>if you wouldn't post it on social media, don't paste it into a commercial AI.</strong></p>
            </div>
        </div>

        <!-- ===== LEARNING & GROWTH ===== -->
        <h2 class="faq-section-title reveal">Learning &amp; Growth</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Use AI to Skip the Learning Process</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>In education and learning, <strong>the process is often as important as the result itself</strong>. When you struggle with a math problem, the struggle builds neural pathways. When you draft and redraft an essay, you develop your voice. When you debug code line by line, you learn to think systematically. These processes don't just produce outcomes &mdash; they <em>build you</em>.</p>
                <p>AI can give you the answer to almost any homework question in seconds. But having the answer without understanding how to get there is like <strong>having a map without learning to navigate</strong> &mdash; the moment you face a new terrain, you're lost. The student who uses AI to skip the learning steps ends up with a grade but without the knowledge, and that gap eventually shows up in ways that matter: in exams, in job performance, in life.</p>
                <p>This applies beyond school. A musician who uses AI to generate compositions without learning music theory never develops the ear. A programmer who copies AI code without understanding it can't debug or adapt it. A writer who lets AI draft everything never finds their own voice.</p>
                <p>The right way to use AI in learning is as a <strong>tutor, not a shortcut</strong>:</p>
                <ul>
                    <li><strong>Ask AI to explain</strong> concepts you don't understand, step by step</li>
                    <li><strong>Ask it to quiz you</strong> and give you practice problems</li>
                    <li><strong>Do the work yourself first,</strong> then ask AI to review and suggest improvements</li>
                    <li><strong>Use AI to explore deeper</strong> &mdash; "Why does this formula work?" or "What's the intuition behind this?"</li>
                    <li><strong>Ask it to teach you the method,</strong> not give you the answer</li>
                </ul>
                <p>AI is the best tutor humanity has ever had &mdash; patient, available, knowledgeable. <strong>Use it to learn more, not to learn less.</strong></p>
            </div>
        </div>

        <!-- ===== ETHICS & INTEGRITY ===== -->
        <h2 class="faq-section-title reveal">Ethics &amp; Integrity</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Use AI to Impersonate Others or Plagiarize</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>Oscar Wilde once said, <em>"Imitation is the sincerest form of flattery that mediocrity can pay to greatness."</em> There's truth in that &mdash; we all learn by studying those who came before us. But there's a crucial difference between <strong>being inspired by someone and pretending to be them</strong>.</p>
                <p>AI makes it trivially easy to mimic someone's writing style, replicate their artistic voice, or generate content that looks like it came from someone else. But doing so isn't just ethically wrong &mdash; it's a <strong>missed opportunity</strong>. You can always do better than a copy. Even when you want to emulate a style or a person, the most interesting work comes from improving on it with your own personal nuances, perspectives, and additions.</p>
                <p>The best creative approach is to <strong>combine multiple inspirations with your own originality</strong>. Study three writers you admire, identify what you love about each, and then synthesize those elements with your own voice. Ask AI to help you understand <em>why</em> a style works, then develop your own version that goes further. That's not imitation &mdash; that's evolution.</p>
                <p>As for plagiarism: presenting AI-generated work as entirely your own &mdash; whether in school, at work, or in creative contexts &mdash; is a form of dishonesty that carries real consequences. Beyond the ethical dimension, it also <strong>robs you of growth</strong>. Every piece of work you do yourself, even imperfectly, makes you better. Every piece you fake teaches you nothing.</p>
                <p><strong>Use AI to amplify your voice, not to replace it.</strong></p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Use AI to Generate Misinformation or Manipulate Others</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>AI can generate convincing text, realistic images, persuasive arguments, and even deepfake audio or video. This makes it an extraordinarily powerful tool for <strong>spreading misinformation, creating propaganda, and manipulating people</strong> &mdash; and it's something you should never do.</p>
                <p>Creating fake news articles, fabricating quotes, generating misleading images, writing deceptive reviews, or producing content designed to manipulate emotions or opinions is not just unethical &mdash; it <strong>erodes the trust that society depends on</strong>. When people can no longer tell what's real, everyone suffers: public discourse degrades, institutions lose credibility, and individuals make worse decisions.</p>
                <p>The ease with which AI can produce convincing falsehoods is exactly why we need higher standards of integrity, not lower ones. <strong>Be part of the solution:</strong> use AI to inform, educate, create, and build &mdash; never to deceive.</p>
            </div>
        </div>

        <!-- ===== CRITICAL THINKING ===== -->
        <h2 class="faq-section-title reveal">Critical Thinking &amp; Judgment</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Blindly Trust AI Output</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>AI can sound <strong>incredibly confident while being completely wrong</strong>. It can invent citations that don't exist, fabricate statistics that sound plausible, and present fictional events as historical fact &mdash; all with the same authoritative tone it uses when giving accurate information. This is called "hallucination," and it happens more often than most people realize.</p>
                <p>The danger is compounded by the <strong>authority effect</strong>: because AI responses are articulate, well-structured, and seemingly well-reasoned, we tend to trust them more than we should. It feels like talking to an expert, but it's actually talking to a very sophisticated pattern matcher that doesn't know what it doesn't know.</p>
                <p>Always verify important claims, especially regarding:</p>
                <ul>
                    <li><strong>Facts, dates, and statistics</strong> &mdash; AI frequently makes up numbers and references</li>
                    <li><strong>Legal and regulatory information</strong> &mdash; laws vary by jurisdiction and change frequently</li>
                    <li><strong>Medical and health information</strong> &mdash; wrong information can be dangerous</li>
                    <li><strong>Technical specifications</strong> &mdash; AI can confuse versions, parameters, and compatibility</li>
                    <li><strong>Current events</strong> &mdash; AI's training data has a cutoff date</li>
                </ul>
                <p><strong>Treat AI as a brilliant but unreliable colleague</strong> &mdash; someone whose work you always review before relying on it.</p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Make Critical Decisions Based Solely on AI</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>Whether it's a medical diagnosis, a legal strategy, a major financial investment, or a life-changing personal decision &mdash; <strong>AI should inform your thinking, not replace it</strong>. AI lacks the ability to understand the full context of your unique situation, to weigh intangible human factors, or to take responsibility for the consequences of its suggestions.</p>
                <p>Use AI as <strong>one input among many</strong>. Consult qualified professionals for medical, legal, and financial matters. Talk to people who know you for personal decisions. Gather multiple perspectives. AI can help you prepare better questions, understand complex topics, and explore possibilities &mdash; but the final judgment should always be yours, informed by people with relevant expertise and genuine accountability.</p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Let AI Replace Human Connection</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>AI can simulate conversation, companionship, and even emotional support &mdash; but it cannot replace the genuine warmth, understanding, and growth that come from <strong>real human relationships</strong>. There's a growing concern about people, especially those who are isolated or vulnerable, developing deep attachments to AI chatbots as substitutes for human connection.</p>
                <p>Human relationships are messy, complicated, sometimes frustrating &mdash; and that's exactly what makes them valuable. We grow through disagreement, learn empathy through shared suffering, and build trust through vulnerability. AI can't offer any of this. It can only <strong>simulate the surface of connection</strong> without the substance beneath it.</p>
                <p>Use AI as a tool to <strong>enhance</strong> your human interactions: prepare for a difficult conversation, understand different perspectives, learn communication skills. But don't let it become a substitute for the real thing. <strong>Log off and call a friend.</strong></p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>Don't Assume AI Is Objective or Unbiased</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>AI models are trained on data created by humans &mdash; and humans have biases. These biases inevitably make their way into AI systems: <strong>cultural biases, gender biases, racial biases, political leanings, and worldview assumptions</strong> are all embedded in the training data and, by extension, in the model's responses.</p>
                <p>When AI presents information, it may reflect the dominant perspective in its training data, which is disproportionately Western, English-speaking, and from certain socioeconomic contexts. Topics related to history, culture, politics, religion, and social issues are particularly prone to bias.</p>
                <p>Always consider: <strong>whose perspective is this AI likely reflecting?</strong> Seek out diverse sources and viewpoints beyond what any single AI provides. The appearance of objectivity can be more dangerous than obvious bias &mdash; because it's harder to question something that sounds neutral.</p>
            </div>
        </div>

        <div class="cta-box reveal">
            <h3>AI is a tool &mdash; you are the human</h3>
            <p>The key to using AI well is knowing both its power and its limits. Use AI to do MORE and BETTER &mdash; but always with your judgment, your ethics, and your humanity guiding the way.</p>
            <a href="things.html" class="btn btn-primary">Explore 100+ Things To Do &rarr;</a>
        </div>

    </div>
</section>

</body>
</html>
