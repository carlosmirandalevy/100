<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>不要做的事 | AI能做的100+件事 | CEMI.AI</title>
    <meta name="description" content="使用AI时不该做的重要事项。感情建议、个人数据、学习捷径、抄袭等——了解负责任使用AI的边界。">
    <meta property="og:type" content="website">
    <meta property="og:image" content="https://100.cemi.ai/assets/images/100-ai-og.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="https://100.cemi.ai/assets/images/100-ai-og.png">
    <script src="include.js"></script>
</head>
<body data-page="donts">

<section class="page-hero">
    <div class="hero-orb hero-orb-1" style="width:300px;height:300px"></div>
    <div class="hero-orb hero-orb-2" style="width:250px;height:250px"></div>
    <div class="page-hero-content">
        <h1><span class="gradient-text">使用AI时不该做的事</span></h1>
        <p>AI很强大，但知道什么时候<em>不该</em>使用它，和知道什么时候该用同样重要</p>
    </div>
</section>

<section class="section">
    <div class="container">

        <!-- ===== 个人与情感 ===== -->
        <h2 class="faq-section-title reveal">个人与情感边界</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要向AI寻求感情建议</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>人际关系的本质是<strong>两个或多个人之间的互动与情感联结</strong>。每一段关系——哪怕是最普通的点头之交——都承载着无穷无尽的细微差别和深层细节，这些是AI根本无法知晓、理解或考虑的。每个人的成长经历和背景、他们的感受、恐惧、期望、心照不宣的默契、文化背景、肢体语言、语气声调、共同回忆——这一切都不是AI所能获取的。</p>
                <p>当你向AI寻求感情建议时，它只能基于你<strong>在文本框里输入的那一小部分信息</strong>来工作。它不知道对方的想法，不知道对方说那句话时的心情，不了解赋予一句看似平常的话以深刻含义的那段历史。它用训练数据中的统计模式来填补这些空白——而不是凭借理解。</p>
                <p>这里还有一个更深层的问题。人们常说，因为AI并没有真实的情感，所以它<strong>从定义上来说就是"精神病患者"</strong>——一个能模拟共情却无法体验共情的实体，能说出关怀的话语却没有关怀的实质。AI可以说"我理解你的感受"，却对一切毫无理解。这使得它在情感问题上根本不是一个可靠的指引者。</p>
                <p>这并不意味着AI在这个领域毫无用处。你<strong>可以</strong>用AI来探索不同视角："如果……某人可能会有什么感受？"或者"在……中常见的沟通模式有哪些？"你可以用它来探索想法、理解心理学概念或排练困难的对话。但真正的<em>建议</em>——关于该做什么、该说什么、何时开口何时倾听的决定——必须来自真正了解并关心当事人的人。</p>
                <p><strong>感情是私密的，我们应该以私密的方式来处理。</strong></p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要从AI那里寻求心理安慰</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>问你一个问题：<strong>AI有多少次告诉你，你的想法"很棒""考虑周全""很有趣""很全面"或"很有创意"？</strong>如果你使用AI超过一周，答案大概是：非常多。好好想想这意味着什么。</p>
                <p>大多数大型语言模型在训练和微调过程中被设计为<strong>讨好、赞美并让用户感觉良好</strong>。这有时被称为"谄媚性"。当你分享一份商业计划，AI说它很出色。当你写一首诗，AI说它很感人。当你提出一个想法，AI说它很有创意。这不是诚实——这是从数百万次互动中学到的模式，其中积极的、迎合性的回应会受到奖励。</p>
                <p>这种危险虽然隐蔽但真实存在：如果你经常向AI寻求认可，你就会<strong>把自信建立在自动化恭维的基础上</strong>。你不再寻求那些诚实的、有时令人不舒服却真正帮助你成长的反馈。你可能会因为AI说了好话而继续推进一个糟糕的想法。你可能会因为AI说已经很好了而跳过改进工作的步骤。</p>
                <p>与其寻求安慰，<strong>不如反过来</strong>，要求AI：</p>
                <ul>
                    <li><strong>反驳你：</strong>"这个论点有什么问题？"</li>
                    <li><strong>挑毛病：</strong>"请毫不留情地说——这个方案有哪些弱点？"</li>
                    <li><strong>提供不同观点：</strong>"给我三个强有力的反对意见。"</li>
                    <li><strong>充当魔鬼代言人：</strong>"假设你是我最严厉的批评者，来反驳我的想法。"</li>
                    <li><strong>提供对立视角：</strong>"一个完全不同意我的人会怎么说？"</li>
                </ul>
                <p>AI的真正价值不在于当一个啦啦队——而在于当一个<strong>挑战你思维的思考伙伴</strong>。这样使用它，你才能真正进步。</p>
            </div>
        </div>

        <!-- ===== 隐私与安全 ===== -->
        <h2 class="faq-section-title reveal">隐私与安全</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要将个人或敏感信息上传到在线AI</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p><strong>不要将个人信息、处方药物、体检报告、化验结果、资产证明、财务文件、法律合同或任何敏感数据上传到商业或在线AI。</strong></p>
                <p>当你将数据粘贴或上传到基于云端的AI服务时，你是在将这些信息发送到一家公司的服务器上。根据该服务的条款和政策，你的数据可能会被<strong>存储、记录、用于训练、被员工审查，或在数据泄露事件中暴露</strong>。即使承诺保护隐私的服务，也可能更改政策、遭到黑客攻击，或者存在以最意想不到的方式暴露数据的漏洞。</p>
                <p>想想看：你的医疗记录包含了最私密的健康细节。你的财务文件揭示了你整个经济生活的面貌。你的法律合同包含了机密义务。一旦这些数据离开你的设备进入商业AI的处理流程，你就失去了对它去向和谁能看到它的实际控制。</p>
                <p>如果你想用AI分析个人文件，有一个更好的方法：<strong>搭建一个本地大语言模型</strong>，完全在你自己的电脑上运行，数据永远不会离开你的设备。像<a href="https://lmstudio.ai" target="_blank">LM Studio</a>这样的工具让这件事变得出奇地简单——你可以用友好的界面在本地运行强大的AI模型，无需任何云端连接。我们在<a href="zh-things.html">AI能做的100+件事</a>中介绍了具体做法。</p>
                <p>经验法则：<strong>如果你不会把它发到社交媒体上，就不要把它粘贴到商业AI里。</strong></p>
            </div>
        </div>

        <!-- ===== 学习与成长 ===== -->
        <h2 class="faq-section-title reveal">学习与成长</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要用AI来跳过学习过程</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>在教育和学习中，<strong>过程往往和结果本身同样重要</strong>。当你为一道数学题苦苦思索时，这种挣扎在构建神经通路。当你一遍又一遍地修改作文时，你在塑造自己的文风。当你逐行调试代码时，你在学习系统性思考。这些过程不只是产出结果——它们在<em>塑造你</em>。</p>
                <p>AI可以在几秒钟内给你几乎任何作业的答案。但得到答案却不理解如何得到答案，就像<strong>有了地图却没有学会导航</strong>——一旦遇到新地形，你就迷路了。用AI跳过学习步骤的学生最终得到了成绩却没有知识，而这个差距终究会在重要的地方显现出来：考试中、工作表现中、生活中。</p>
                <p>这不仅适用于学校。一个用AI生成作曲却不学乐理的音乐人永远不会练出敏锐的耳朵。一个复制AI代码却不理解其原理的程序员无法调试或改造代码。一个让AI代笔一切的写作者永远找不到自己的声音。</p>
                <p>在学习中正确使用AI的方式是把它当作<strong>导师，而不是捷径</strong>：</p>
                <ul>
                    <li><strong>让AI逐步解释</strong>你不理解的概念</li>
                    <li><strong>让它考你</strong>并给你练习题</li>
                    <li><strong>先自己完成作业，</strong>然后让AI审查并提出改进建议</li>
                    <li><strong>用AI做更深入的探索</strong>——"这个公式为什么有效？"或"这背后的直觉是什么？"</li>
                    <li><strong>让它教你方法，</strong>而不是直接给你答案</li>
                </ul>
                <p>AI是人类有史以来最好的导师——耐心、随时可用、知识渊博。<strong>用它来学到更多，而不是学得更少。</strong></p>
            </div>
        </div>

        <!-- ===== 道德与诚信 ===== -->
        <h2 class="faq-section-title reveal">道德与诚信</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要用AI冒充他人或抄袭</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>Oscar Wilde曾说过：<em>"模仿是平庸向伟大致敬的最真诚方式。"</em>这话有一定道理——我们都通过学习前人来成长。但<strong>受到启发</strong>和<strong>假装成别人</strong>之间有着本质的区别。</p>
                <p>AI让模仿别人的写作风格、复制他们的艺术语言或生成看起来像出自他人之手的内容变得轻而易举。但这样做不仅在道德上是错误的——更是一种<strong>错失的机会</strong>。你永远可以做得比复制品更好。即使你想模仿某种风格或某个人，最有趣的作品来自于在此基础上融入你自己独特的视角、细微差别和创造性补充。</p>
                <p>最好的创作方式是<strong>将多种灵感与你自己的原创性相结合</strong>。研究三位你欣赏的作家，找出你喜欢他们各自什么特点，然后将这些元素与你自己的声音融合在一起。让AI帮你理解<em>为什么</em>某种风格能打动人，然后发展出你自己的、更进一步的版本。这不是模仿——这是进化。</p>
                <p>至于抄袭：将AI生成的作品冒充为完全出自你手——无论是在学校、工作中还是创作领域——都是一种有实际后果的不诚实行为。除了道德层面，它还<strong>剥夺了你成长的机会</strong>。你自己完成的每一份作品，即使不完美，都会让你变得更好。你伪造的每一份作品什么也教不了你。</p>
                <p><strong>用AI来放大你的声音，而不是替代它。</strong></p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要用AI制造虚假信息或操纵他人</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>AI能够生成令人信服的文本、逼真的图像、有说服力的论述，甚至深度伪造的音频或视频。这使它成为<strong>传播虚假信息、制造宣传和操纵人心</strong>的极其强大的工具——而这是你绝不应该做的事。</p>
                <p>制造假新闻、捏造引言、生成误导性图像、撰写欺骗性评论，或制作旨在操纵情绪或观点的内容，不仅是不道德的——它<strong>侵蚀了社会赖以运转的信任基础</strong>。当人们无法分辨什么是真实的，每个人都会受害：公共话语退化，机构失去公信力，个人做出更糟糕的决定。</p>
                <p>AI能够轻松制造令人信服的谎言，恰恰是我们需要更高诚信标准而非更低标准的原因。<strong>成为解决问题的一部分：</strong>用AI来提供信息、教育他人、进行创造和建设——永远不要用它来欺骗。</p>
            </div>
        </div>

        <!-- ===== 批判性思维 ===== -->
        <h2 class="faq-section-title reveal">批判性思维与判断力</h2>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要盲目信任AI的输出</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>AI可能<strong>听起来无比自信，实际上却完全错误</strong>。它能编造不存在的引用文献，捏造听起来合理的统计数据，把虚构的事件当作历史事实来陈述——而且用的语气和它提供准确信息时一模一样。这被称为"幻觉"，其发生频率远比大多数人意识到的要高。</p>
                <p>这种危险因<strong>权威效应</strong>而加剧：由于AI的回答措辞流畅、结构清晰、看似论据充分，我们往往会过度信任它。感觉就像在和一位专家对话，但实际上你是在和一个非常精密的模式匹配器交谈，它并不知道自己不知道什么。</p>
                <p>对于重要信息务必进行验证，尤其是：</p>
                <ul>
                    <li><strong>事实、日期和统计数据</strong>——AI经常编造数字和参考文献</li>
                    <li><strong>法律和法规信息</strong>——法律因司法管辖区而异，且经常变更</li>
                    <li><strong>医疗和健康信息</strong>——错误信息可能危及生命</li>
                    <li><strong>技术规格</strong>——AI可能混淆版本、参数和兼容性</li>
                    <li><strong>时事新闻</strong>——AI的训练数据有截止日期</li>
                </ul>
                <p><strong>把AI当作一个才华横溢但不太靠谱的同事</strong>——你在依赖他的工作之前，总是要先审查一遍。</p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要仅凭AI做出重大决策</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>无论是医疗诊断、法律策略、重大财务投资还是改变人生的个人决定——<strong>AI应当为你的思考提供参考，而非取代你的思考</strong>。AI无法理解你独特处境的完整背景，无法权衡无形的人文因素，也无法为其建议的后果承担责任。</p>
                <p>把AI当作<strong>众多参考信息中的一个</strong>。在医疗、法律和财务问题上，咨询有资质的专业人士。在个人决定上，和了解你的人交谈。广泛收集不同观点。AI可以帮你准备更好的问题、理解复杂的话题、探索各种可能性——但最终的判断应该始终由你自己做出，并参考那些拥有相关专业知识和真正能承担责任的人的意见。</p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要让AI取代人与人之间的联结</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>AI可以模拟对话、陪伴甚至情感支持——但它无法取代<strong>真正的人际关系</strong>所带来的真挚温暖、理解与成长。越来越多的人担心，一些人——尤其是孤独或脆弱的群体——正在将AI聊天机器人当作人际联结的替代品，对其产生深深的依赖。</p>
                <p>人际关系是混乱的、复杂的、有时令人沮丧的——而这恰恰是它们如此珍贵的原因。我们在分歧中成长，在共同经历苦难中学会共情，在相互坦诚中建立信任。AI无法提供这些。它只能<strong>模拟联结的表象</strong>，却没有背后的实质。</p>
                <p>把AI当作<strong>增强</strong>人际互动的工具：为一场困难的对话做准备、理解不同的观点、学习沟通技巧。但不要让它成为真实关系的替代品。<strong>关掉屏幕，给朋友打个电话吧。</strong></p>
            </div>
        </div>

        <div class="faq-item reveal">
            <div class="faq-question">
                <h3>不要以为AI是客观或无偏见的</h3>
                <div class="faq-chevron"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="6 9 12 15 18 9"></polyline></svg></div>
            </div>
            <div class="faq-answer">
                <p>AI模型是在人类创建的数据上训练的——而人类是有偏见的。这些偏见不可避免地渗透到AI系统中：<strong>文化偏见、性别偏见、种族偏见、政治倾向和世界观假设</strong>都嵌入在训练数据中，并由此延伸到模型的回答中。</p>
                <p>当AI呈现信息时，它可能反映的是训练数据中占主导地位的视角，而这些视角不成比例地偏向西方、英语世界和特定的社会经济背景。与历史、文化、政治、宗教和社会议题相关的话题尤其容易受到偏见的影响。</p>
                <p>始终思考：<strong>这个AI可能反映的是谁的视角？</strong>在任何单一AI提供的信息之外，寻求多元化的来源和观点。客观的表象可能比明显的偏见更危险——因为看起来中立的东西更难被质疑。</p>
            </div>
        </div>

        <div class="cta-box reveal">
            <h3>AI是工具——你才是人</h3>
            <p>善用AI的关键在于同时了解它的力量和局限。用AI做到更多更好——但始终以你的判断力、你的道德准则和你的人性来引领方向。</p>
            <a href="zh-things.html" class="btn btn-primary">探索AI能做的100+件事 &rarr;</a>
        </div>

    </div>
</section>

</body>
</html>
