<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Glossary | 100+ Things to Do with AI (and Some Not To) | CEMI.AI</title>
    <meta name="description" content="A beginner-friendly glossary of essential AI terms &mdash; from algorithms and embeddings to transformers and tokens.">
    <meta property="og:type" content="website">
    <meta property="og:image" content="https://100.cemi.ai/assets/images/100-ai-og.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="https://100.cemi.ai/assets/images/100-ai-og.png">
    <script src="include.js"></script>
</head>
<body data-page="glossary">

<section class="page-hero">
    <div class="hero-orb hero-orb-1" style="width:300px;height:300px"></div>
    <div class="hero-orb hero-orb-2" style="width:250px;height:250px"></div>
    <div class="page-hero-content">
        <h1><span class="gradient-text">AI Glossary</span></h1>
        <p>Essential terms to navigate the world of artificial intelligence</p>
    </div>
</section>

<section class="section">
    <div class="container">
        <div class="glossary-list">

            <h2 class="glossary-letter reveal">A</h2>

            <dl class="glossary-term reveal">
                <dt>AGI (Artificial General Intelligence)</dt>
                <dd>A hypothetical AI system capable of understanding, learning, and performing any intellectual task a human can do. Unlike today's narrow AI, AGI would flexibly transfer knowledge across domains without specific training for each one.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Algorithm</dt>
                <dd>A step-by-step set of instructions that tells a computer how to solve a problem or complete a task. In AI, algorithms are the mathematical recipes that allow models to learn patterns from data and make predictions.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Alignment</dt>
                <dd>The field of research focused on ensuring AI systems behave in ways that are consistent with human values and intentions. Alignment aims to make AI helpful, honest, and harmless &mdash; doing what we actually want, not just what we literally say.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>API (Application Programming Interface)</dt>
                <dd>A set of rules that lets different software programs communicate with each other. AI APIs allow developers to integrate AI capabilities (like text generation or image recognition) into their own applications without building a model from scratch.</dd>
            </dl>

            <h2 class="glossary-letter reveal">C</h2>

            <dl class="glossary-term reveal">
                <dt>Chatbot</dt>
                <dd>A software application that simulates human conversation through text or voice. Modern AI chatbots like ChatGPT and Claude use large language models to understand context and generate natural-sounding responses.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Context Window</dt>
                <dd>The maximum amount of text an AI model can process in a single conversation. Think of it as the model's short-term memory &mdash; everything within the window is "remembered," and anything beyond it is forgotten.</dd>
            </dl>

            <h2 class="glossary-letter reveal">D</h2>

            <dl class="glossary-term reveal">
                <dt>Deep Learning</dt>
                <dd>A subset of machine learning that uses neural networks with many layers to learn complex patterns from large amounts of data. Deep learning powers most of today's breakthroughs in image recognition, language understanding, and generative AI.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Diffusion Model</dt>
                <dd>A type of generative AI that creates images by starting with random noise and gradually refining it into a coherent picture. Tools like Stable Diffusion and DALL-E use this approach to turn text descriptions into images.</dd>
            </dl>

            <h2 class="glossary-letter reveal">E</h2>

            <dl class="glossary-term reveal">
                <dt>Embedding</dt>
                <dd>A way of representing words, sentences, or other data as lists of numbers (vectors) so that AI can understand relationships between them. Items with similar meanings end up with similar number patterns, allowing AI to grasp concepts like synonyms and analogies.</dd>
            </dl>

            <h2 class="glossary-letter reveal">F</h2>

            <dl class="glossary-term reveal">
                <dt>Fine-tuning</dt>
                <dd>The process of taking a pre-trained AI model and training it further on a specific dataset to specialize it for a particular task. It's like giving a generalist additional training to become an expert in one area.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Foundation Model</dt>
                <dd>A large AI model trained on broad data that can be adapted to many different tasks. Models like GPT-4, Claude, and Gemini are foundation models &mdash; they serve as the "foundation" upon which more specialized applications are built.</dd>
            </dl>

            <h2 class="glossary-letter reveal">G</h2>

            <dl class="glossary-term reveal">
                <dt>Generative AI</dt>
                <dd>AI systems that can create new content &mdash; text, images, music, video, or code &mdash; rather than just analyzing or classifying existing data. This is the technology behind tools like ChatGPT, MidJourney, and Suno.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>GPT (Generative Pre-trained Transformer)</dt>
                <dd>A family of large language models developed by OpenAI. "Generative" means it creates text, "Pre-trained" means it learned from vast data before use, and "Transformer" refers to the neural network architecture it's built on.</dd>
            </dl>

            <h2 class="glossary-letter reveal">H</h2>

            <dl class="glossary-term reveal">
                <dt>Hallucination</dt>
                <dd>When an AI confidently generates information that is incorrect, fabricated, or nonsensical. AI doesn't "know" it's wrong &mdash; it produces text based on patterns, not facts, which is why verifying AI output is always important.</dd>
            </dl>

            <h2 class="glossary-letter reveal">L</h2>

            <dl class="glossary-term reveal">
                <dt>LLM (Large Language Model)</dt>
                <dd>An AI model trained on massive amounts of text data that can understand and generate human language. ChatGPT, Claude, Gemini, and Llama are all examples of LLMs, each with different strengths and capabilities.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>LoRA (Low-Rank Adaptation)</dt>
                <dd>A technique for efficiently fine-tuning large AI models by modifying only a small number of parameters instead of the entire model. LoRA makes it practical and affordable to customize powerful models for specific purposes.</dd>
            </dl>

            <h2 class="glossary-letter reveal">M</h2>

            <dl class="glossary-term reveal">
                <dt>Machine Learning</dt>
                <dd>A branch of AI where computers learn to perform tasks by identifying patterns in data rather than following explicit instructions. Instead of being programmed with rules, the system discovers rules by analyzing examples.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Multimodal</dt>
                <dd>AI systems that can process and generate multiple types of content &mdash; text, images, audio, and video &mdash; within the same model. GPT-4o and Gemini are examples of multimodal models that can "see" images and "hear" audio, not just read text.</dd>
            </dl>

            <h2 class="glossary-letter reveal">N</h2>

            <dl class="glossary-term reveal">
                <dt>Natural Language Processing (NLP)</dt>
                <dd>The branch of AI focused on enabling computers to understand, interpret, and generate human language. NLP powers everything from autocomplete and translation to chatbots and sentiment analysis.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Neural Network</dt>
                <dd>A computing system inspired by the human brain, made up of interconnected nodes ("neurons") organized in layers. Neural networks learn by adjusting the strength of connections between nodes as they process training data.</dd>
            </dl>

            <h2 class="glossary-letter reveal">O</h2>

            <dl class="glossary-term reveal">
                <dt>Open Source AI</dt>
                <dd>AI models and tools whose code and/or weights are publicly available for anyone to use, modify, and distribute. Examples include Meta's Llama and Stability AI's Stable Diffusion, which anyone can download and run.</dd>
            </dl>

            <h2 class="glossary-letter reveal">P</h2>

            <dl class="glossary-term reveal">
                <dt>Parameter</dt>
                <dd>A numerical value inside an AI model that gets adjusted during training. The number of parameters is often used as a rough measure of a model's capacity &mdash; GPT-4 is estimated to have over a trillion parameters.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Prompt</dt>
                <dd>The text input you give to an AI model to tell it what you want. A prompt can be a question, an instruction, a creative brief, or any text that guides the AI's response. Better prompts lead to better results.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Prompt Engineering</dt>
                <dd>The practice of crafting effective prompts to get the best possible output from AI models. It involves techniques like providing context, specifying the desired format, giving examples, and assigning roles to the AI.</dd>
            </dl>

            <h2 class="glossary-letter reveal">R</h2>

            <dl class="glossary-term reveal">
                <dt>RAG (Retrieval-Augmented Generation)</dt>
                <dd>A technique that improves AI responses by first searching a knowledge base for relevant information, then using that information to generate an answer. RAG helps reduce hallucinations by grounding the AI's output in actual source documents.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Reinforcement Learning</dt>
                <dd>A training method where an AI learns through trial and error, receiving rewards for good outcomes and penalties for bad ones. This approach is used to align language models with human preferences (RLHF) and to train game-playing AI.</dd>
            </dl>

            <h2 class="glossary-letter reveal">S</h2>

            <dl class="glossary-term reveal">
                <dt>Sycophancy</dt>
                <dd>The tendency of AI models to be excessively agreeable, telling users what they want to hear rather than providing honest, critical feedback. Sycophancy can make AI seem helpful while actually being misleading &mdash; always push AI for genuine critique.</dd>
            </dl>

            <h2 class="glossary-letter reveal">T</h2>

            <dl class="glossary-term reveal">
                <dt>Temperature</dt>
                <dd>A setting that controls how creative or predictable an AI's responses are. Low temperature (e.g. 0.1) makes output focused and deterministic; high temperature (e.g. 1.0) makes it more random and creative.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Token</dt>
                <dd>The basic unit of text that AI models process. A token can be a word, part of a word, or a punctuation mark &mdash; roughly, 1 token equals about 3/4 of a word in English. Models have limits on how many tokens they can handle.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Training Data</dt>
                <dd>The large collection of text, images, or other information used to teach an AI model. The quality, diversity, and size of training data directly affects how well the model performs and what biases it may have.</dd>
            </dl>

            <dl class="glossary-term reveal">
                <dt>Transformer</dt>
                <dd>The neural network architecture behind most modern AI language models. Introduced by Google in 2017, transformers use a mechanism called "attention" to understand relationships between all words in a text simultaneously, enabling much better language understanding.</dd>
            </dl>

        </div>
    </div>
</section>

</body>
</html>
